{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4f917ae",
   "metadata": {},
   "source": [
    "## Numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9570758f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda, float32\n",
    "import numpy as np\n",
    "import math\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3eeaf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity timer\n",
    "def event_time(func, n_warm=20,n_time=20):\n",
    "    for i in range(n_warm):\n",
    "        func()\n",
    "    cuda.synchronize()\n",
    "    evtstart = cuda.event(timing=True)\n",
    "    evtend = cuda.event(timing=True)\n",
    "    evtstart.record()\n",
    "    for i in range(n_time):\n",
    "        func()\n",
    "    evtend.record()\n",
    "    evtend.synchronize()\n",
    "    time_ms = cuda.event_elapsed_time(evtstart, evtend)/n_time\n",
    "    print(f'Elapsed time using events: {time_ms:.2f}ms')\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8905f877",
   "metadata": {},
   "source": [
    "## CUDA - The importance of choosing an appropriate thread block size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63473de8",
   "metadata": {},
   "source": [
    "Even when using a naive [unblocked](https://numba.pydata.org/numba-doc/dev/cuda/examples.html) matrix mult kernel it is important to choose an appropriate thread block size to avoid wasting performance.\n",
    "\n",
    "There is a delicate interplay between thread block size and perfomance which is heavily dependant on the CUDA kernel.  This depends on the memory access pattern, the device architechture, shared memory usage etc.  To simplify matters we will just investigate the effect of two parameters which can make an impact when using a simple [kernel](https://numba.pydata.org/numba-doc/dev/cuda/examples.html) with no shared memory usage \n",
    "1. memory [coalescing](https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#coalesced-access-to-global-memory) and,\n",
    "2. utilized threads\n",
    "\n",
    "while maintaingin full occupancy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a727dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 784), (784, 10), (50000, 10))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_sz = (50000,784)\n",
    "weights_sz= (x_train_sz[1],10)\n",
    "x_train = np.random.rand(*x_train_sz);\n",
    "weights = np.random.rand(*weights_sz);\n",
    "r = np.zeros((x_train_sz[0],weights_sz[1]))\n",
    "t = x_train@weights\n",
    "m1g,m2g,rg = map(cuda.to_device,(x_train,weights,r))\n",
    "m1g.shape,m2g.shape,rg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "709c6313",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def matmul(a,b,c):\n",
    "    i, j = cuda.grid(2)\n",
    "    if i < c.shape[0] and j < c.shape[1]:\n",
    "        tmp = 0.\n",
    "        for k in range(a.shape[1]): tmp += a[i, k] * b[k, j]\n",
    "        c[i,j] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cd286c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_blocks(threads,dst_shape):\n",
    "    blocks = (math.ceil(dst_shape[0] / threads[0]), math.ceil(dst_shape[1] / threads[1]))\n",
    "    print(f'Grid - yBlocks: {blocks[0]}, xBlocks: {blocks[1]}, Threads per block - y: {threads[0]}, x: {threads[1]}')\n",
    "    return blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29779ace",
   "metadata": {},
   "source": [
    "Original thread block size 16x16.  \n",
    "1. Writes will be uncoalesced (line size is 128 bytes, 32*sizeof(float), ideally thread block should have 32 x threads).\n",
    "2. 6 = 16 - 10 threads will be wasted per row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bc5f62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid - yBlocks: 3125, xBlocks: 1, Threads per block - y: 16, x: 16\n"
     ]
    }
   ],
   "source": [
    "rg = cuda.to_device(r)\n",
    "threads = (16,16)\n",
    "blocks = calc_blocks(threads,rg.shape)\n",
    "matmul[blocks,threads](m1g,m2g,rg)\n",
    "test_close(t,rg.copy_to_host())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b212cf79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.73 ms ± 45.1 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10 \n",
    "matmul[blocks,threads](m1g,m2g,rg)\n",
    "cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4cfe9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time using events: 5.53ms\n"
     ]
    }
   ],
   "source": [
    "event_time(lambda: matmul[blocks,threads](m1g,m2g,rg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27cc002",
   "metadata": {},
   "source": [
    "What happens when we waste more threads per row, try block size 1x512.\n",
    "1. Writes still uncoalesced (line size is 128 bytes, 32*sizeof(float), ideally thread block should have 32 x threads).\n",
    "2. 502 = 512 - 10 threads will be wasted per row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "561d208f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid - yBlocks: 50000, xBlocks: 1, Threads per block - y: 1, x: 256\n"
     ]
    }
   ],
   "source": [
    "rg = cuda.to_device(r)\n",
    "threads = (1,256)\n",
    "blocks = calc_blocks(threads,rg.shape)\n",
    "matmul[blocks,threads](m1g,m2g,rg)\n",
    "test_close(t,rg.copy_to_host())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48711894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 ms ± 38.2 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10 \n",
    "matmul[blocks,threads](m1g,m2g,rg)\n",
    "cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "afd9ac73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time using events: 14.61ms\n"
     ]
    }
   ],
   "source": [
    "event_time(lambda: matmul[blocks,threads](m1g,m2g,rg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5e09ac",
   "metadata": {},
   "source": [
    "What if we reduce cache hits by reading from new memory locations in m1g in every thread.\n",
    "1. Writes still uncoalesced (line size is 128 bytes, 32*sizeof(float), ideally thread block should have 32 x threads)\n",
    "2. 0 threads will be wasted per row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a37ac520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid - yBlocks: 196, xBlocks: 10, Threads per block - y: 256, x: 1\n"
     ]
    }
   ],
   "source": [
    "rg = cuda.to_device(r)\n",
    "threads = (256,1)\n",
    "blocks = calc_blocks(threads,rg.shape)\n",
    "matmul[blocks,threads](m1g,m2g,rg)\n",
    "test_close(t,rg.copy_to_host())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93b14a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.3 ms ± 60.8 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10 \n",
    "matmul[blocks,threads](m1g,m2g,rg)\n",
    "cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f57ded00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time using events: 39.86ms\n"
     ]
    }
   ],
   "source": [
    "event_time(lambda: matmul[blocks,threads](m1g,m2g,rg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61385aa6",
   "metadata": {},
   "source": [
    "Transpose the matrices so we can use blocks of n*32 threads to coalesce the writes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa28c8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b/mambaforge/lib/python3.9/site-packages/numba/cuda/dispatcher.py:488: NumbaPerformanceWarning: \u001b[1mGrid size 25 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((784, 50000), (10, 784), (10, 50000))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tT = weights.transpose()@x_train.transpose()\n",
    "m1gT = m1g.transpose()\n",
    "m2gT = m2g.transpose()\n",
    "rgT = rg.transpose()\n",
    "m1gT.shape,m2gT.shape,rgT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "47c3ab26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid - yBlocks: 10, xBlocks: 196, Threads per block - y: 1, x: 256\n"
     ]
    }
   ],
   "source": [
    "rgT = cuda.to_device(rg.transpose())\n",
    "threads = (1,256)\n",
    "blocks = calc_blocks(threads,rgT.shape)\n",
    "matmul[blocks,threads](m2gT,m1gT,rgT)\n",
    "test_close(tT,rgT.copy_to_host())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8f706e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.48 ms ± 148 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10 \n",
    "matmul[blocks,threads](m2gT,m1gT,rgT)\n",
    "cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "89226660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time using events: 3.41ms\n"
     ]
    }
   ],
   "source": [
    "event_time(lambda: matmul[blocks,threads](m2gT,m1gT,rgT))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
